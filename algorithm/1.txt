package main

import (
	"encoding/csv"
	"fmt"
	"io"
	"math"
	"os"
	"strconv"
)

func sigmoid(x float64) (s float64) {
	s = 1 / (1 + math.Exp(-x))
	return
}

func d_sigmoid(x float64) (s float64) {
	s = 1 / (1 + math.Exp(-x))
	s = s * (1 - s)
	return
}

func fit(X [][]float64, D [750]float64, Epochs int) (Errors [10000]float64) {
	rows := len(X)
	Weight := [6]float64{0.1, 0.9, 0.2, 0.8, 0.3, 0.7}
	Learning_Factor := 0.5
	Bias := [3]float64{1, 1, 1}
	Epoch := 0
	var Error_total float64

	for Epoch < Epochs {
		j := 0
		//Itirate the epochs
		for j < rows {

			//-----------------------Propagation--------------------------
			//We calculate the total net input of the hidden layer
			net_h1 := (Weight[0] * X[j][0]) + (Weight[1] * X[j][1]) + Bias[0]
			net_h2 := (Weight[2] * X[j][0]) + (Weight[3] * X[j][1]) + Bias[1]

			//Execute the sigmoid activation function in the first layer
			out_h1 := sigmoid(net_h1)
			out_h2 := sigmoid(net_h2)

			//We calculate the total net output of the output layer
			net_y := (Weight[4] * out_h1) + (Weight[5] * out_h2) + Bias[2]

			//We execute the sigmoid activation function in the output layer
			out_y := sigmoid(net_y)

			//-----------------------WE CALCULATE THE TOTAL ERROR-------------------------
			error_real := D[j] - out_y
			Error_total = 0.5 * ((D[j] - out_y) * (D[j] - out_y))

			//------------------------------BACKPROPAGATION-------------------------------
			//Delta rule in output layer
			delta_y := d_sigmoid(net_y) * error_real

			//We adjust the weights of the output layer
			Weight[4] = Weight[4] + (out_h1 * Learning_Factor * delta_y)
			Weight[5] = Weight[5] + (out_h2 * Learning_Factor * delta_y)

			//We adjust the bias
			Bias[2] = Bias[2] + (Learning_Factor * delta_y)

			//Delta rule in the hide layer
			delta_h1 := d_sigmoid(net_h1) * Weight[4] * delta_y
			delta_h2 := d_sigmoid(net_h2) * Weight[5] * delta_y

			//We adjust the weights of the input layer
			Weight[0] = Weight[0] + (delta_h1 * X[j][0] * Learning_Factor)
			Weight[1] = Weight[1] + (delta_h1 * X[j][1] * Learning_Factor)
			Weight[2] = Weight[2] + (delta_h1 * X[j][0] * Learning_Factor)
			Weight[3] = Weight[3] + (delta_h2 * X[j][1] * Learning_Factor)

			//We adjust the bias of the hidden layer
			Bias[0] = Bias[0] + (Learning_Factor * delta_y)
			Bias[1] = Bias[1] + (Learning_Factor * delta_y)

			j += 1
		}

		Errors[Epoch] = Error_total
		Epoch += 1
	}
	return
}

func main() {
	var slice = make([][]float64, 750)
	var D [750]float64

	//Open the file
	open_file, err := os.Open("data.csv")
	if err != nil {
		fmt.Println(err)
	} else {
		fmt.Println("Successfully Opened CSV file")
	}

	//Read the file
	read_file := csv.NewReader(open_file)

	tmp := 0
	for {
		data, err := read_file.Read()
		if err == io.EOF {
			break
		} else if err != nil {
			fmt.Println(err)
		} else {
			//Age
			age, err := strconv.ParseFloat(data[0], 64)
			if err != nil {
				fmt.Println(err)
			}

			//Gender
			var gender float64
			if data[1] == "F" {
				gender = 1
			} else {
				gender = 0
			}

			slice[tmp] = []float64{age, gender}

			//Output
			door := data[5] == "alta"
			if door == true {
				D[tmp] = 1

			} else {
				D[tmp] = 0
			}
			tmp = tmp + 1
		}
	}

	//
	fmt.Println(fit(slice, D, 10000))
}
